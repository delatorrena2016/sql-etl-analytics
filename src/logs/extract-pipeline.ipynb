{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0565c99d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:00:01.037654Z",
     "iopub.status.busy": "2023-10-22T21:00:01.037654Z",
     "iopub.status.idle": "2023-10-22T21:00:01.052452Z",
     "shell.execute_reply": "2023-10-22T21:00:01.051452Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.01897,
     "end_time": "2023-10-22T21:00:01.054622",
     "exception": false,
     "start_time": "2023-10-22T21:00:01.035652",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# declare a list tasks whose products you want to use as inputs\n",
    "upstream = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cda37e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:00:01.060623Z",
     "iopub.status.busy": "2023-10-22T21:00:01.060623Z",
     "iopub.status.idle": "2023-10-22T21:00:01.067101Z",
     "shell.execute_reply": "2023-10-22T21:00:01.067101Z"
    },
    "papermill": {
     "duration": 0.011765,
     "end_time": "2023-10-22T21:00:01.069391",
     "exception": false,
     "start_time": "2023-10-22T21:00:01.057626",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "product = {\"nb\": \"C:\\\\Users\\\\padro\\\\OneDrive\\\\Desktop\\\\ploomber\\\\sql-etl-analytics\\\\sql-etl-analytics\\\\src\\\\logs\\\\extract-pipeline.ipynb\", \"data\": \"C:\\\\Users\\\\padro\\\\OneDrive\\\\Desktop\\\\ploomber\\\\sql-etl-analytics\\\\sql-etl-analytics\\\\src\\\\data\\\\adidas.duckdb\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e05efc9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:00:01.072393Z",
     "iopub.status.busy": "2023-10-22T21:00:01.072393Z",
     "iopub.status.idle": "2023-10-22T21:00:05.672609Z",
     "shell.execute_reply": "2023-10-22T21:00:05.671666Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 4.60326,
     "end_time": "2023-10-22T21:00:05.673651",
     "exception": false,
     "start_time": "2023-10-22T21:00:01.070391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Date: 2020-01-01 00:00:00\n",
      "Last Date: 2021-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kaggle\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "\n",
    "# Check if 'data' folder exists, if not, create it\n",
    "# Set the path relative to the script\n",
    "def extract_data(dataset_id, data_dir, file_name):\n",
    "    \"\"\"Extract data from URL and return a dataframe\"\"\"\n",
    "    # Check if 'data' folder exists, if not, create it\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "    # Download data from Kaggle and save it to 'data' folder\n",
    "    kaggle.api.authenticate()\n",
    "    kaggle.api.dataset_download_files(dataset_id, path=data_dir, unzip=True)\n",
    "\n",
    "    if \"csv\" in file_name:\n",
    "        df = pd.read_csv(f'{data_dir}/{file_name}')\n",
    "    elif \"xlsx\" in file_name and \"Adidas\" in file_name:\n",
    "        df = pd.read_excel(f'{data_dir}/{file_name}', sheet_name=\"Data Sales Adidas\", skiprows=range(4), usecols=\"B:N\")\n",
    "    else: \n",
    "        df = pd.DataFrame()\n",
    "    return df\n",
    "\n",
    "def extract_unique_season_and_category(df):\n",
    "    #create a copy\n",
    "    df_copy_2 = df.copy()\n",
    "\n",
    "    # Extract unique values for 'Season' and 'Category' columns\n",
    "    unique_seasons = df_copy_2['Season'].unique()\n",
    "    unique_categories = df_copy_2['Category'].unique()\n",
    "    \n",
    "    print(\"Unique Seasons:\", unique_seasons)\n",
    "    print(\"Unique Categories:\", unique_categories)\n",
    "\n",
    "    return df_copy_2\n",
    "\n",
    "def save_to_duckdb(df, table_name, db_path):\n",
    "    \"\"\"Save dataframe to duckdb\"\"\"\n",
    "    conn = duckdb.connect(db_path)\n",
    "    conn.register('df', df)\n",
    "    \n",
    "    # Check if table already exists, if not, create it\n",
    "    tables = conn.execute(\"SHOW TABLES\").fetchall()\n",
    "    if table_name not in [table[0] for table in tables]:\n",
    "        conn.execute(f\"CREATE TABLE {table_name} AS SELECT * FROM df\")\n",
    "    \n",
    "    conn.close()\n",
    "\n",
    "# Get range of data dates\n",
    "def data_cleaning_and_saving(df):\n",
    "    df_copy = df.copy()\n",
    "    # Get the start date (oldest date)\n",
    "    start_date = df_copy['Invoice Date'].min()\n",
    "\n",
    "    # Get the last date\n",
    "    last_date = df_copy['Invoice Date'].max()\n",
    "\n",
    "    print(\"Start Date:\", start_date)\n",
    "    print(\"Last Date:\", last_date)\n",
    "\n",
    "    df_copy['Invoice Date'] = pd.to_datetime(df['Invoice Date'])\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # First data extraction from URL\n",
    "    kaggle_id = 'heemalichaudhari/adidas-sales-dataset'\n",
    "    data_dir = os.path.join('.', 'src/data')\n",
    "    file_name_adidas = \"Adidas US Sales Datasets.xlsx\"\n",
    "    df_adidas = extract_data(kaggle_id,data_dir, file_name_adidas)\n",
    "    clean_df_adidas = data_cleaning_and_saving(df_adidas)\n",
    "    \n",
    "    table_name = 'data_sales_adidas'\n",
    "    # Save the cleaned data to DuckDB\n",
    "    save_to_duckdb(df_adidas, table_name, f'{data_dir}/adidas.duckdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c777a81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:00:05.677367Z",
     "iopub.status.busy": "2023-10-22T21:00:05.677367Z",
     "iopub.status.idle": "2023-10-22T21:00:09.689312Z",
     "shell.execute_reply": "2023-10-22T21:00:09.689312Z"
    },
    "papermill": {
     "duration": 4.01599,
     "end_time": "2023-10-22T21:00:09.691341",
     "exception": false,
     "start_time": "2023-10-22T21:00:05.675351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Seasons: ['Winter' 'Spring' 'Summer' 'Fall']\n",
      "Unique Categories: ['Clothing' 'Footwear' 'Outerwear' 'Accessories']\n"
     ]
    }
   ],
   "source": [
    "    # Second data extraction from URL\n",
    "    kaggle_id = 'iamsouravbanerjee/customer-shopping-trends-dataset'\n",
    "    file_name_trends  = \"shopping_trends.csv\"\n",
    "    df_trends = extract_data(kaggle_id,data_dir, file_name_trends)\n",
    "    clean_df_trends = extract_unique_season_and_category(df_trends)\n",
    "    \n",
    "    table_name = 'data_shopping_trends'\n",
    "    # Save the cleaned data to DuckDB\n",
    "    save_to_duckdb(clean_df_trends, table_name, f'{data_dir}/adidas.duckdb')\n",
    "\n",
    "    \n",
    "\n",
    "    # Third data extraction from URL\n",
    "    kaggle_id = 'kaushiksuresh147/adidas-vs-nike'\n",
    "    file_name  = \"Adidas Vs Nike.csv\"\n",
    "    df = extract_data(kaggle_id,data_dir, file_name)\n",
    "    \n",
    "    table_name = 'data_adidasvsnike'\n",
    "    # Save the cleaned data to DuckDB\n",
    "    save_to_duckdb(df, table_name, f'{data_dir}/adidas.duckdb')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "duration": 10.203962,
   "end_time": "2023-10-22T21:00:09.926403",
   "exception": null,
   "input_path": "C:\\Users\\padro\\AppData\\Local\\Temp\\tmpfmtf1c0d.ipynb",
   "output_path": "C:\\Users\\padro\\OneDrive\\Desktop\\ploomber\\sql-etl-analytics\\sql-etl-analytics\\src\\logs\\extract-pipeline.ipynb",
   "parameters": {
    "product": {
     "data": "C:\\Users\\padro\\OneDrive\\Desktop\\ploomber\\sql-etl-analytics\\sql-etl-analytics\\src\\data\\adidas.duckdb",
     "nb": "C:\\Users\\padro\\OneDrive\\Desktop\\ploomber\\sql-etl-analytics\\sql-etl-analytics\\src\\logs\\extract-pipeline.ipynb"
    }
   },
   "start_time": "2023-10-22T20:59:59.722441"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
